{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\chrome\\chromedriver.exe\"\n",
    "service = Service(executable_path = path)\n",
    "driver = webdriver.Chrome(service = service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Website : [bbs.bt](https://www.bbs.bt/dzongkha/)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bbs.bt.com\n",
    "urls = []\n",
    "file = open(\"urls.txt\", \"r\")\n",
    "urls = file.readlines()\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    headline = driver.find_element(By.CSS_SELECTOR,'[data-td-block-uid=\"tdi_86\"]').find_element(By.TAG_NAME, 'h1').text\n",
    "    div = driver.find_element(By.CSS_SELECTOR, '[data-td-block-uid=\"tdi_88\"]')\n",
    "\n",
    "    paragraphs = div.find_elements(By.TAG_NAME, 'p')\n",
    "    article = \"\"\n",
    "\n",
    "    for para in paragraphs:\n",
    "        article += f\"{para.text}\\n\"\n",
    "\n",
    "    f = open(f\"{headline}.txt\",\"w\", encoding=\"utf-8\" )\n",
    "    f.write(article)\n",
    "    f.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Website: [KuenselOnline](https://kuenselonline.com/category/dzongkha/)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://kuenselonline.com/category/dzongkha/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Fetching all the links from each page.\n",
    "links = []\n",
    "while True:\n",
    "\n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[class=\"category\"]')\n",
    "    anchor = div.find_elements(By.TAG_NAME,'a')\n",
    "    for i in anchor:\n",
    "        links.append(i.get_attribute('href'))\n",
    "\n",
    "    # Clicking the next Button if there.\n",
    "    try:\n",
    "        ul = driver.find_element(By.CSS_SELECTOR, '[class = \"page-numbers\"]')\n",
    "        button = driver.find_element(By.CSS_SELECTOR,'[class=\"next page-numbers\"]')\n",
    "        button.click()\n",
    "    except:\n",
    "        try:\n",
    "            ul = driver.find_element(By.CSS_SELECTOR, '[class = \"page-numbers\"]')\n",
    "            button = driver.find_element(By.CSS_SELECTOR,'[class=\"next page-numbers\"]')\n",
    "            button.click()\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links:\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    # Fetch Headline\n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[class=\"page-header\"]')\n",
    "    headline = div.find_element(By.CSS_SELECTOR, '[class=\"post-title single-topic\"]').get_attribute('innerText')\n",
    "\n",
    "    # Fetch Content\n",
    "    div = driver.find_element(By.CSS_SELECTOR, '[class=\"content-wrapper\"]')\n",
    "    paragraph = div.find_elements(By.TAG_NAME, 'p')\n",
    "    article = \"\"\n",
    "\n",
    "    for para in paragraph:\n",
    "        article += para.get_attribute('innerText') + '\\n'\n",
    "\n",
    "    try:\n",
    "        file = open(f\"./Raw_Dataset/kuenselonline/{headline}.txt\",\"w\",encoding=\"utf-8\" )\n",
    "    except:\n",
    "        charcters = ['#','%','&','{','}','<','>', '*','?','/', '$' ,'!', \"'\" ,'\"' ,':','@','+','`','|','=','\\\\']\n",
    "        for i in charcters:\n",
    "            headline = headline.replace(i,'')\n",
    "    file = open(f\"./Raw_Dataset/kuenselonline/{headline}.txt\",\"w\",encoding=\"utf-8\" )\n",
    "\n",
    "    file.write(article)\n",
    "    file.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Website: [Mandala Text](https://texts.mandala.library.virginia.edu/book_pubreader/44111/)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headings = []\n",
    "# articles = []\n",
    "\n",
    "# # article_tag = driver.find_element(By.TAG_NAME,'article')\n",
    "# # sections = article_tag.find_elements(By.TAG_NAME,'section')\n",
    "# # for section in sections:\n",
    "# #     head = section.find_element(By.TAG_NAME,'h3').text\n",
    "# #     div = section.find_element(By.CSS_SELECTOR,'[class=\"tex2jax\"]')\n",
    "# #     paragraphs = div.find_elements(By.TAG_NAME, 'p')\n",
    "\n",
    "# #     article = \"\"\n",
    "\n",
    "# #     for para in paragraphs:\n",
    "# #         article += para.text + '\\n'\n",
    "# #     headings.append(head)\n",
    "# #     articles.append(article)\n",
    "url = \"https://texts.mandala.library.virginia.edu/book_pubreader/44111/\"\n",
    "driver.get(url)\n",
    "\n",
    "main = driver.find_element(By.CSS_SELECTOR,'[id=\"jr-content\"]').text\n",
    "file = open(\"./Raw_Dataset/Others/mandala text.txt\",\"w\",encoding=\"utf-8\" )\n",
    "file.write(main)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i> Website: [Universal Declaration Of Human Rights](http://efele.net/udhr/d/udhr_dzo.txt)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://efele.net/udhr/d/udhr_dzo.txt\"\n",
    "driver.get(url)\n",
    "\n",
    "heading = \"Universal Declaration of Human Rights\"\n",
    "content = driver.find_element(By.TAG_NAME,'pre').text\n",
    "\n",
    "file = open(f\"./Raw_Dataset/Others/{heading}.txt\", \"w\", encoding = 'utf-8')\n",
    "file.write(content)\n",
    "file.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Website : [Wikipedia](dz.wikipedia.org)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting Urls\n",
    "links = []\n",
    "\n",
    "url = \"https://www.google.com/search?q=site:dz.wikipedia.org\"\n",
    "driver.get(url)\n",
    "\n",
    "while True:\n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[id=\"center_col\"]')\n",
    "\n",
    "    divs = div.find_elements(By.CLASS_NAME, 'MjjYud')\n",
    "    # div_last = div.find_elements(By.CSS_SELECTOR, '[class=\"hlcw0c\"]')\n",
    "\n",
    "    for url in divs:\n",
    "        a_tag = url.find_elements(By.TAG_NAME, 'a')\n",
    "        for a in a_tag:\n",
    "            links.append(a.get_attribute('href'))\n",
    "\n",
    "    next_page = driver.find_element(By.CSS_SELECTOR, '[id=\"botstuff\"]')\n",
    "    \n",
    "    try :\n",
    "        button = next_page.find_element(By.CSS_SELECTOR, '[id=\"pnnext\"]')\n",
    "        button.click()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Invalid Link\n",
    "invalid = \"https://translate.google.com/translate?hl=en&sl=ru&u=https://dz.wikipedia.org/wiki/%25E0%25BC%25A2%25E0%25BC%25A0%25E0%25BC%25A0%25E0%25BC%25A0&prev=search&pto=aue\"\n",
    "links.remove(invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawling Data\n",
    "for url in links:\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[class=\"mw-content-container\"]')\n",
    "    header = div.find_element(By.TAG_NAME, 'header')\n",
    "    heading = header.find_element(By.TAG_NAME, 'h1').text\n",
    "\n",
    "    div = div.find_element(By.CSS_SELECTOR, '[class=\"mw-body-content\"]')\n",
    "\n",
    "    file = open(f\"./Raw_Dataset/wikipedia/{heading}.txt\", \"w\", encoding = 'utf-8')\n",
    "    file.write(div.text)\n",
    "    file.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Website: [Bible](https://www.bible.com/et/bible/3157/MAT.1.DZOD)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bible.com/et/bible/3157/MAT.1.DZOD\"\n",
    "driver.get(url)\n",
    "heading = \"temp\"\n",
    "while True:\n",
    "\n",
    "    div = driver.find_element(By.CSS_SELECTOR, '[data-testid=\"chapter-content\"]')\n",
    "    heading = div.find_element(By.TAG_NAME, 'h1').text\n",
    "\n",
    "    file = open(f\"./Raw_Dataset/Bible/{heading}.txt\", \"w\", encoding = 'utf-8')\n",
    "    file.write(div.text)\n",
    "    file.close()\n",
    "\n",
    "    time.sleep(2)\n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[class=\"w-[90vw] flex sticky bottom-[30%] z-1 justify-between max-w-[1000px] pointer-events-none mx-auto\"]')\n",
    "    buttons = div.find_elements(By.CSS_SELECTOR,'[class=\"[pointer-events:all]\"]')\n",
    "\n",
    "    try:\n",
    "        buttons[1].find_element(By.TAG_NAME,'a').click()\n",
    "    except:\n",
    "         break\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Google Translate</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://translate.google.co.in\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down = driver.find_element(By.CSS_SELECTOR, '[class=\"akczyd\"]')\n",
    "drop_down.find_element(By.TAG_NAME, 'button').click()\n",
    "\n",
    "container = driver.find_element(By.CSS_SELECTOR,'[jsrenderer=\"Sx55ld\"]')\n",
    "div = container.find_element(By.CSS_SELECTOR,'[class=\"vSUSRc\"]')\n",
    "div1 = div.find_element(By.CSS_SELECTOR,'[class=\"F29iQc\"]')\n",
    "spans = div1.find_elements(By.CSS_SELECTOR, '[class=\"OQo6Zd\"]')\n",
    "\n",
    "# # print(len(languages))\n",
    "for span in spans:\n",
    "    divs = span.find_elements(By.TAG_NAME, 'div')\n",
    "    print(divs[-1].text)\n",
    "    # if(divs[-1].text == 'Dzongkha'):\n",
    "    #     divs[0].click()\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Pandas DataFrame our our entire Data.\n",
    "import os\n",
    "path = './Raw_Dataset/Bhutantimes/temp'\n",
    "files = os.listdir(path)\n",
    "\n",
    "for file_name in files:\n",
    "\n",
    "    file_path = os.path.join(path,file_name)\n",
    "    file = open(file_path,\"r\",encoding = 'utf-8')\n",
    "    article = file.readlines()\n",
    "    file.close()\n",
    "    count = 0\n",
    "    input = \"\"\n",
    "    output =\"\"\n",
    "    for sentence in article:\n",
    "        if count+len(sentence) <= 5000:\n",
    "            input += sentence\n",
    "            count += len(sentence)\n",
    "            continue\n",
    "\n",
    "        text_box = driver.find_element(By.CSS_SELECTOR, '[class=\"ccvoYb\"]')\n",
    "        input_box = text_box.find_element(By.CSS_SELECTOR, '[jsname=\"ZdXDJ\"]').find_element(By.TAG_NAME, 'textarea')\n",
    "        input_box.send_keys(input)\n",
    "        \n",
    "        count = 0\n",
    "        input = sentence\n",
    "\n",
    "        time.sleep(10)\n",
    "        output_box = text_box.find_element(By.CSS_SELECTOR, '[class=\"KkbLmb\"]').find_element(By.CSS_SELECTOR,'[class=\"HwtZe\"]')\n",
    "        output += output_box.text\n",
    "        \n",
    "        time.sleep(2)\n",
    "        div = driver.find_element(By.CSS_SELECTOR,'[class=\"DVHrxd\"]')\n",
    "        div1 = div.find_element(By.TAG_NAME,'span')\n",
    "        # div1 = div.find_element(By.CSS_SELECTOR,'class=\"VfPpkd-Bz112c-RLmnJb\"')\n",
    "        button = div1.find_element(By.TAG_NAME, 'button')\n",
    "        try:\n",
    "            button.click()\n",
    "        except:\n",
    "            time.sleep(2)\n",
    "            div = driver.find_element(By.CSS_SELECTOR,'[class=\"DVHrxd\"]')\n",
    "            # div1 = div.find_element(By.CSS_SELECTOR,'[jsname=\"Fs81Kd\"]')\n",
    "            div1 = div.find_element(By.TAG_NAME,'span')\n",
    "            button = div1.find_element(By.TAG_NAME, 'button')\n",
    "            button.click()\n",
    "\n",
    "    file = open(f\"./Raw_Dataset/Bhutantimes/data/{file_name}.txt\", \"w\", encoding = 'utf-8')\n",
    "    file.write(output)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../Raw_Dataset_1/temp.txt\", \"r\", encoding = 'utf-8')\n",
    "article = file.readlines()\n",
    "file.close()\n",
    "\n",
    "count = 0\n",
    "input = \"\"\n",
    "output =\"\"\n",
    "for sentence in article:\n",
    "    if count+len(sentence) <= 5000:\n",
    "        input += sentence\n",
    "        count += len(sentence)\n",
    "        continue\n",
    "\n",
    "    text_box = driver.find_element(By.CSS_SELECTOR, '[class=\"ccvoYb\"]')\n",
    "    input_box = text_box.find_element(By.CSS_SELECTOR, '[jsname=\"ZdXDJ\"]').find_element(By.TAG_NAME, 'textarea')\n",
    "    input_box.send_keys(input)\n",
    "    \n",
    "    count = 0\n",
    "    input = sentence\n",
    "\n",
    "    time.sleep(6)\n",
    "    output_box = text_box.find_element(By.CSS_SELECTOR, '[class=\"KkbLmb\"]').find_element(By.CSS_SELECTOR,'[class=\"HwtZe\"]')\n",
    "    output += output_box.text\n",
    "    \n",
    "    div = driver.find_element(By.CSS_SELECTOR,'[class=\"DVHrxd\"]')\n",
    "    div1 = div.find_element(By.CSS_SELECTOR,'[jsname=\"Fs81Kd\"]')\n",
    "    button = div1.find_element(By.TAG_NAME, 'button')\n",
    "    try:\n",
    "        button.click()\n",
    "    except:\n",
    "        time.sleep(2)\n",
    "        div = driver.find_element(By.CSS_SELECTOR,'[class=\"DVHrxd\"]')\n",
    "        div1 = div.find_element(By.CSS_SELECTOR,'[jsname=\"Fs81Kd\"]')\n",
    "        button = div1.find_element(By.TAG_NAME, 'button')\n",
    "        button.click()\n",
    "\n",
    "file = open(\"../Raw_Dataset_1/temp1.txt\", \"w\", encoding = 'utf-8')\n",
    "file.write(output)\n",
    "file.close()\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = driver.find_element(By.CSS_SELECTOR,'[class=\"DVHrxd\"]')\n",
    "div1 = div.find_element(By.CSS_SELECTOR,'[jsname=\"Fs81Kd\"]')\n",
    "button = div1.find_element(By.TAG_NAME, 'button')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../Raw_Dataset_1/temp.txt\", \"w\", encoding = 'utf-8')\n",
    "file.write(output)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"Hi my name is michael\"\n",
    "text_box = driver.find_element(By.CSS_SELECTOR, '[class=\"ccvoYb\"]')\n",
    "input_box = text_box.find_element(By.CSS_SELECTOR, '[jsname=\"ZdXDJ\"]').find_element(By.TAG_NAME, 'textarea')\n",
    "input_box.send_keys(temp)\n",
    "\n",
    "time.sleep(2)\n",
    "output_box = text_box.find_element(By.CSS_SELECTOR, '[class=\"KkbLmb\"]').find_element(By.CSS_SELECTOR,'[class=\"HwtZe\"]')\n",
    "# driver.execute_script('arguments[0].lang = \"dz\";', output_box)\n",
    "# driver.close()\n",
    "print(output_box.text)\n",
    "driver.find_element(By.CSS_SELECTOR, '[class=\"VfPpkd-Bz112c-LgbsSe VfPpkd-Bz112c-LgbsSe-OWXEXe-e5LLRc-SxQuSe yHy1rc eT1oJ mN1ivc ZihNHd GA2I6e\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Bhutan Times</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dailybhutan.com/category/news/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all the urls.\n",
    "file = open(\"./Raw_Dataset/Bhutantimes/urls.txt\", \"a\", encoding = 'utf-8')\n",
    "\n",
    "div = driver.find_element(By.CSS_SELECTOR,'[class=\"content-area pvt0\"]')\n",
    "a = div.find_elements(By.TAG_NAME,('a'))\n",
    "for i in a:\n",
    "    file.write(f\"{i.get_attribute('href')}\\n\")\n",
    "\n",
    "file.close()\n",
    "# a[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetching Articles\n",
    "file = open(\"./Raw_Dataset/Bhutantimes/urls.txt\", \"r\", encoding = 'utf-8')\n",
    "links = (file.readlines())\n",
    "file.close()\n",
    "\n",
    "for i,url in enumerate(links):\n",
    "    temp =\"\"\n",
    "    for j in range(0,len(url)-1):\n",
    "        temp += url[j]\n",
    "    print(temp)\n",
    "    driver.get(temp)\n",
    "    time.sleep(1)\n",
    "    file = open(f\"./Raw_Dataset/Bhutantimes/temp/file{i+1}.txt\", \"w\", encoding = 'utf-8')\n",
    "    try:\n",
    "        file.write(driver.find_element(By.CSS_SELECTOR,'[class=\"col-sm-9 single\"]').text)\n",
    "    except:\n",
    "        continue\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Uploading on Hugging Face</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploding on Hugging Face \n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path =\"./Raw_Dataset\",\n",
    "    path_in_repo=\"Raw_Dataset\",\n",
    "    repo_id=\"druvpat/Dzongkha_Dataset\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
